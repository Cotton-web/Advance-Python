{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cotton-web/Advance-Python/blob/main/advance_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug9hEd3cB5Jp"
      },
      "source": [
        "**Assignment 6**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qubkfIfts-SB"
      },
      "source": [
        "**Q1**. Create a file that contains 1000 lines of random strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a9Tf_HZ0AnV8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=10):\n",
        "  return ''.join(random.sample(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "file=\"ran_strings.txt\"\n",
        "with open(file, 'w') as f:\n",
        "  for i in range(1000):\n",
        "    random_string = generate_random_string()\n",
        "    f.write(random_string + '\\n')\n",
        "print(f\"File '{f}' has been created with 1000 random strings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95hVg6xTtyyh"
      },
      "source": [
        "**Q2.** Create a file that contains multiple lines of random strings and file size should be less than 5 mb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtOT-PaBFmYX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def random_string(length=100):\n",
        "  return ''.join(random.sample(string.ascii_letters+string.digits,k=length))\n",
        "file=\"random_strings5mb.txt\"\n",
        "with open (file, 'w') as f:\n",
        "  while os.path.getsize(file)<5*1024*1024:\n",
        "    random_string = generate_random_string()\n",
        "    f.write(random_string + '\\n')\n",
        "print(f\"File has been created with 5MB of random strings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWukt4d4t6F5"
      },
      "source": [
        "**Q3.** Create 10 files that contains multiple lines of random strings and file  size of each file must be 5 mb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twmd6s__Tb9t"
      },
      "outputs": [],
      "source": [
        "for i in range(1,11):\n",
        "  file_name=f\"random_strings_{i}.txt\"\n",
        "  with open(file_name,'w') as f:\n",
        "    while os.path.getsize(file_name)<5*1024*1024:\n",
        "      f.write(random_string + \"\\n\")\n",
        "  print(f\"File '{file_name}' created with a size of approximately 5 mb.\")\n",
        "print(\"All 10 files have been successfully created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3avrzgluY2x"
      },
      "source": [
        "**Q4.** Create 5 files of size 1mb, 2mb, 3mb, 4mb  and 5mb ; file contains multiple lines of random strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-6H_Qs3dcxu"
      },
      "outputs": [],
      "source": [
        "#4\n",
        "import os\n",
        "file_sizes=[1,2,3,4,5]\n",
        "for size in file_sizes:\n",
        "  file_name=f\"random_strings-{size}MB.txt\"\n",
        "  with open(file_name,'w' ) as f:\n",
        "    while os.path.getsize(file_name)<size*1024*1024:\n",
        "      f.write(random_string + \"\\n\")\n",
        "  print(f\"File '{file_name}' created with a size of {size}MB.\")\n",
        "print(\"All files have been successfully created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiXpTYNuxAY"
      },
      "source": [
        "**Q5.** Convert all files of q4 into upper case one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-WVwu_leGXP"
      },
      "outputs": [],
      "source": [
        "#5\n",
        "for size in file_sizes:\n",
        "  file_name=f\"random_strings-{size}MB.txt\"\n",
        "  new_file=f\"uppercase_{size}MB.txt\"\n",
        "  with open(file_name,'r') as f:\n",
        "    with open(new_file,'w') as new_f:\n",
        "      for line in f:\n",
        "        new_line=line.upper()\n",
        "        new_f.write(new_line)\n",
        "      print(f\"File '{new_file}' created with uppercase strings.\")\n",
        "print(\"All files have been successfully created!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Convert all the files of Q4 into upper case parallel using multi-threading.\n"
      ],
      "metadata": {
        "id": "Vs4pbm1JbiY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# List of files from Q4\n",
        "file_sizes = [1, 2, 3, 4, 5]\n",
        "file_names = [f\"random_strings-{size}MB.txt\" for size in file_sizes]\n",
        "\n",
        "def convert_file_to_upper(file_name):\n",
        "    new_file_name = file_name.replace(\".txt\", \"_UPPER.txt\")\n",
        "    with open(file_name, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    with open(new_file_name, 'w') as f:\n",
        "        f.write(content.upper())\n",
        "\n",
        "    print(f\"File '{file_name}' converted to upper case as '{new_file_name}'.\")\n",
        "\n",
        "# Run the conversion in parallel\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    executor.map(convert_file_to_upper, file_names)\n",
        "\n",
        "print(\"All files have been converted to upper case in parallel.\")\n"
      ],
      "metadata": {
        "id": "8h2uU8gOeRWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. WAP to automatically download 10 images of cat from “Google Images”. [Hint: Find the package from pypi.org and use it]"
      ],
      "metadata": {
        "id": "3LaT8IYPeGq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Google-Images-Search"
      ],
      "metadata": {
        "id": "KtMysAzebIMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_search import GoogleImagesSearch\n",
        "import zipfile\n",
        "import os\n",
        "# you can provide API key and CX using arguments,\n",
        "# or you can set environment variables: GCS_DEVELOPER_KEY, GCS_CX\n",
        "gis = GoogleImagesSearch('AIzaSyCGyqf36D5k3QghaZLhAqb1R2OUtRFraF8' , '0d386b282da5209ea' , validate_images=True)\n",
        "def search(keyword, imageNumber):\n",
        "    _search_params = {\n",
        "        'q': keyword,\n",
        "        'num': imageNumber,\n",
        "        # 'safe': 'medium',\n",
        "        # 'fileType': 'jpg',\n",
        "        # 'imgType': 'photo',\n",
        "        # 'imgSize': 'MEDIUM',\n",
        "        # 'imgDominantColor': 'brown',\n",
        "        # 'rights': 'cc_publicdomain'\n",
        "    }\n",
        "\n",
        "    gis.search(search_params=_search_params, path_to_dir='./images/')\n",
        "\n",
        "search('cat',10)"
      ],
      "metadata": {
        "id": "T_n27FaRdQlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDKskatjDBng"
      },
      "source": [
        "**II.  Data Analysis**\n",
        "\n",
        "**Q 12.**Create a random dataset of 100 rows and 30 columns. All the values are defined between [1,200]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxmNIor0e3Ka"
      },
      "outputs": [],
      "source": [
        "import pandas  as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQcylMDbD5Y8"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(np.random.randint(1,200,size=(100,30)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XSORZ-yFhkZ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0x_ldVKXGV4"
      },
      "source": [
        "**(i) Replace all the values with NA in the dataset defined between [10, 60]. Print the count of number rows having missing values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDgR8wMVNqz-"
      },
      "outputs": [],
      "source": [
        "df=df.mask((df>=10) & (df<=60),np.nan)\n",
        "na_rows=df.isnull().sum()\n",
        "print(\"Number of rows with missing values:\")\n",
        "print(na_rows)\n",
        "print(\"Total number of rows having missing values : \",na_rows.sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig2K5TkfXMaC"
      },
      "source": [
        "**(ii) Replace all the NA values with the average of the column value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgqQBs9oWnCW"
      },
      "outputs": [],
      "source": [
        "df_filled = df.fillna(df.mean())\n",
        "print(df_filled)\n",
        "print(\"Number of rows with missing values:\")\n",
        "print(df_filled.isnull().sum())\n",
        "print(\"Total number of rows having missing values : \",df_filled.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-a8p93lYZpa"
      },
      "source": [
        "**(iii) Find the Pearson correlation among all the columns and plot heat map. Also select those columns having correlation <=0.7.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLtIWSqwYjxL"
      },
      "outputs": [],
      "source": [
        "from textwrap import fill\n",
        "\n",
        "# measures pearson(linear) correlation between columns in a DataFrame\n",
        "corr_matrix= df.corr(method='pearson')\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(corr_matrix,annot=False,cmap='Purples', linewidth=0.5)\n",
        "\n",
        "plt.title('Pearson Correlation Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "correlation_mask= corr_matrix.abs() > 0.7\n",
        "np.fill_diagonal(correlation_mask.values,False)\n",
        "low_corr_columns=correlation_mask.sum(axis=1)==0\n",
        "filtered_df=df.loc[:,low_corr_columns]\n",
        "print(\"Columns with correlation <=0.7 with all other columns:\")\n",
        "print(filtered_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avckTL3yb4tk"
      },
      "source": [
        "**(iv) Normalize all the values in the dataset between 0 and 10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PkN7rOzbxDq"
      },
      "outputs": [],
      "source": [
        "df_normalized=(df-df.min())/(df.max()-df.min())*10\n",
        "print(df_normalized.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg0C35VMckh4"
      },
      "source": [
        "**(v) Replace all the values in the dataset with 1 if value <=0.5 else with 0.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqw24Aalc7uk"
      },
      "outputs": [],
      "source": [
        "cdf_binary=(df_normalized > 0.5 ).astype(int)\n",
        "print(cdf_binary.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ley_IRvMN0Vr"
      },
      "source": [
        "Q13. Create a random dataset of 500 rows and 10 columns.\n",
        "Columns 1 to 4 are defined between [-10, 10];\n",
        "Columns 5 to 8 are defined between [10, 20];\n",
        "Columns 9 to 10 are defined between [-100, 100].\n",
        "Apply following clustering algorithms; determine the optimal number of clusters and plot distance metric\n",
        "graph using each algorithm.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uWxVyJLQ5bS"
      },
      "outputs": [],
      "source": [
        "cols_1_4 = pd.DataFrame(np.random.uniform(-10, 10, size=(500, 4)), columns=[f'Col{i}' for i in range(1, 5)])\n",
        "cols_5_8 = pd.DataFrame(np.random.uniform(10, 20, size=(500, 4)), columns=[f'Col{i}' for i in range(5, 9)])\n",
        "cols_9_10 = pd.DataFrame(np.random.uniform(-100, 100, size=(500, 2)), columns=[f'Col{i}' for i in range(9, 11)])\n",
        "\n",
        "df = pd.concat([cols_1_4, cols_5_8, cols_9_10], axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcdElDEdN6ZG"
      },
      "source": [
        "(i) K-Mean clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y wandb pycaret"
      ],
      "metadata": {
        "id": "HqcKs1trXpg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "O6iUmf7tYDqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_5OA27cSVdV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pycaret.clustering import *\n",
        "import matplotlib.pyplot as plt\n",
        "# ⚙️ Step 4: Initialize PyCaret Clustering Setup\n",
        "setup(data=df, normalize=True)\n",
        "\n",
        "kmeans_model = create_model('kmeans')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHCJuKlsTHpb"
      },
      "outputs": [],
      "source": [
        "# Plot Elbow Curve (to find optimal k)\n",
        "plot_model(kmeans_model, plot='elbow')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_kmeans = create_model('kmeans', num_clusters=8)\n",
        "\n",
        "clustered_data = assign_model(final_kmeans)\n",
        "\n",
        "plot_model(final_kmeans, plot='cluster')\n",
        "\n",
        "clustered_data.head()"
      ],
      "metadata": {
        "id": "KuG4G_NiOqM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import get_config\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = get_config(\"X\")\n",
        "\n",
        "distance_matrix = squareform(pdist(X, metric='euclidean'))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(distance_matrix[:100, :100], cmap='coolwarm')\n",
        "plt.title(\"Distance Matrix Heatmap (KMeans Clustering - 100x100 sample)\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Samples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gl44Of2CYujZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38OyGUyMOAXy"
      },
      "source": [
        "(ii) Hierarchical clustering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pycaret.clustering import *\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "hclust_model = create_model('hclust')"
      ],
      "metadata": {
        "id": "qCD84aLVZKoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_hclust = create_model('hclust', num_clusters=4)\n",
        "hclust_results = assign_model(final_hclust)\n",
        "plot_model(final_hclust, plot='cluster')  # PCA 2D cluster plot"
      ],
      "metadata": {
        "id": "3aIo5iKVZrcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(hclust_model, plot='elbow')"
      ],
      "metadata": {
        "id": "LxhHGUOaaXhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.clustering import get_config\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = get_config(\"X\")\n",
        "\n",
        "distance_matrix = squareform(pdist(X, metric='euclidean'))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(distance_matrix[:100, :100], cmap='BuPu')\n",
        "plt.title(\"Distance Matrix Heatmap (100×100 sample)\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Samples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E4TN80WzahnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Pdm1FVdT4h"
      },
      "source": [
        "**Q14. Create a random dataset of 600 rows and 15 columns. All the values are defined between [-100,100].**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwjJrN4WdV6s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df=pd.DataFrame(np.random.randint(-100,101,size=(600,15)))\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T_EP1lNdTf-"
      },
      "source": [
        "**(i)\n",
        "Plot scatter graph between Column 5 and Column 6.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roeA0PXad5sC"
      },
      "outputs": [],
      "source": [
        "x=df[5]\n",
        "y=df[6]\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(x,y,alpha=1,color='pink',edgecolor='purple')\n",
        "plt.xlabel('Column 5')\n",
        "plt.ylabel('Column 6')\n",
        "plt.title('Scatter Plot of Column 5 vs Column 6')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkaIUkLcezG4"
      },
      "source": [
        "**(ii) Plot histogram of each column in single graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M1ZQB2vedBz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,12))\n",
        "for column in df.columns:\n",
        "  plt.hist(df[column],bins=20,alpha=0.7,label=column)\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Each Column')\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl7HP4eAftQP"
      },
      "source": [
        "**(iii) Plot the Box plot of each column in single graph.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cR8AwnxfzUQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,12))\n",
        "sns.boxplot(data=df)\n",
        "plt.xlabel('Column')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Box Plot of Each Column')\n",
        "plt.xticks(rotation=45)                 #rotates x-axis tick labels by 45 degrees to improve readability\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}